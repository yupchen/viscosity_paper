{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#50 ms 2*2 binning 100% power green channel ####preprocessing: fiji image->adjust->bleach correction-> simple ratio. 60pix rolling background subtraction. 60%~99.99%. ##### hitogram matching ; adjust contrast 67% to 99.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, unicode_literals, print_function  # for compatibility with Python 2 and 3\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# change the following to %matplotlib notebook for interactive plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Optionally, tweak styles.\n",
    "mpl.rc('figure',  figsize=(10, 5))\n",
    "mpl.rc('image', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series  # for convenience\n",
    "import os\n",
    "\n",
    "import pims\n",
    "import trackpy as tp\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from IPython import display\n",
    "from scipy.optimize import curve_fit, least_squares\n",
    "\n",
    "import tifffile\n",
    "import diptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(f,xdata,ydata,popt):\n",
    "\n",
    "    residuals = ydata- f(xdata, *popt)\n",
    "    ss_res = np.sum(residuals**2)\n",
    "    ss_tot = np.sum((ydata-np.mean(ydata))**2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    return r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some environment and scaling variables\n",
    "current_folder = os.getcwd()\n",
    "folder = current_folder\n",
    "output_folder = folder+'/micro_traces/' # output folder\n",
    "#os.mkdir(output_folder)  # uncomment this line for creating the output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [ '041822_dilution_concentrated_100nm']\n",
    "experiment_folder = folder+'/'+experiments[0]+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_files = []\n",
    "for file in os.listdir(experiment_folder):\n",
    "    if ('tif' in file) & ('_extract_a_100nm_' in file):\n",
    "        extract_files.append(file)\n",
    "extract_files.sort(key=lambda f: int(f.split('act_a_100nm_')[1].split('_RAW_ch00')[0]) )\n",
    "conc_files = []\n",
    "for file in os.listdir(experiment_folder):\n",
    "    if ('tif' in file) & ('_concentrated_a_100nm_' in file):\n",
    "        conc_files.append(file)\n",
    "conc_files.sort(key=lambda f: int(f.split('concentrated_a_100nm_')[1].split('_RAW_ch00')[0]) )\n",
    "files = extract_files+conc_files\n",
    "for file in files:\n",
    "    print(file)\n",
    "#compile file for flatfield\n",
    "tifffile_shape = tifffile.imread(experiment_folder+files[0]).shape\n",
    "\n",
    "stack = tifffile.imread(experiment_folder+files[0], key=(0,tifffile_shape[0]-1 ,20))\n",
    "for file in files[1:]:\n",
    "    frames = tifffile.imread(experiment_folder+file, key=(0,tifffile_shape[0]-1 ,20))\n",
    "    stack = np.concatenate((stack,frames))\n",
    "tifffile.imwrite('for_flat_field.tif',stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatfield = pims.open(experiment_folder+'Flat_field.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tp.locate(np_frames[0], 7, invert=False, minmass = 250) #, minmass=50000)#130000)\n",
    "f = tp.batch(np_frames[:300], 7, minmass=250);#50000);#130000, invert=False);\n",
    "t = tp.link(f, 25, memory=3)\n",
    "t1 = tp.filter_stubs(t, 10)\n",
    "# Compare the number of particles in the unfiltered and filtered data.\n",
    "print('Before:', t['particle'].nunique())\n",
    "print('After:', t1['particle'].nunique())\n",
    "\n",
    "t2 = t1[((t1['mass'] > 100) & (t1['size'] < 5.0) )]\n",
    "if len(t2) > 0:\n",
    "    plt.figure(figsize = [10,10])\n",
    "    tp.plot_traj(t2);\n",
    "    plt.show()\n",
    "    \n",
    "plt.figure(figsize = [15,15])\n",
    "#tp.annotate(f, frames[i])\n",
    "plt.imshow(frames[0])\n",
    "#plt.plot(f['x']+5,f['y']+5,'.')\n",
    "plt.plot(f.loc[f['frame']==0]['x']+5,f.loc[f['frame']==0]['y'],'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(f['mass'], bins=np.linspace(0,500,100) ) #(0,150000,100))\n",
    "\n",
    "# Optionally, label the axes.\n",
    "ax.set(xlabel='mass', ylabel='count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t = tp.link(f, 10, memory=3)\n",
    "t1 = tp.filter_stubs(t, 10)\n",
    "# Compare the number of particles in the unfiltered and filtered data.\n",
    "#print('Before:', t['particle'].nunique())\n",
    "#print('After:', t1['particle'].nunique())\n",
    "\n",
    "t2 = t1[((t1['mass'] > 100) & (t1['size'] < 5.0) )]\n",
    "plt.figure()\n",
    "plt.xlim(0,2000)\n",
    "tp.mass_size(t.groupby('particle').mean())\n",
    "tp.mass_size(t.groupby('particle').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray(image):\n",
    "    return image[:, :]/2  # [:,:,1]Take just the green channel\n",
    "\n",
    "fps = 308/86.038 #300/89.811 #367/110.249# 490/151.515\n",
    "voxel = 0.322 \n",
    "list_ns = []\n",
    "list_As = []\n",
    "list_ims = []\n",
    "list_ems = []\n",
    "list_ds = []\n",
    "list_t2s = []\n",
    "list_file_records = []\n",
    "\n",
    "\n",
    "#for selected in [0]:#range(len(experiments)):\n",
    "    #experiment_folder = current_folder+'/'+experiments[selected]\n",
    "    #files = []\n",
    "    #for file in os.listdir(experiment_folder):\n",
    "    #    if 'tif' in file:\n",
    "    #        files.append(file)\n",
    "            \n",
    "    #try:\n",
    "    #    files.sort(key=lambda f: int(f.split('_A_')[1].split('_')[0]) )\n",
    "    #except:\n",
    "    #    print('aoe') #it used to be continue and skipped the ATP experiments\n",
    "#for file in files: \n",
    "#    print(file)\n",
    "tp.quiet()\n",
    "ns = []\n",
    "As = []\n",
    "ims = []\n",
    "ems = []\n",
    "ds = []\n",
    "t2s = []\n",
    "file_records = []\n",
    "\n",
    "#search_ranges = np.tile(np.linspace(25,15,11),2)\n",
    "search_ranges = np.concatenate((np.array([20]),np.linspace(20,10,6),np.linspace(20,5,11))) #search_ranges = np.concatenate((np.array([25]),np.linspace(25,15,6),np.linspace(25,5,11)))\n",
    "norm_flatfield = flatfield/np.mean(flatfield)\n",
    "\n",
    "for i in range(len(files)):\n",
    "    print(files[i])\n",
    "    frames = pims.open(experiment_folder+'/'+files[i])\n",
    "    overall_mean = np.mean(frames)\n",
    "    np_frames = np.ones(np.shape(frames))\n",
    "    for j,frame in enumerate(frames):\n",
    "        norm_frame = frame*overall_mean/np.mean(frame)/norm_flatfield\n",
    "        np_frames[j] = (norm_frame-np.percentile(np.array(norm_frame),50)).astype(int)\n",
    "    np_frames = np_frames[0:150]\n",
    "    \n",
    "    diameter = 15\n",
    "    maxsize = 7\n",
    "    minmass =650\n",
    "    percentile = 99.5\n",
    "    topn = 300\n",
    "\n",
    "    f = tp.locate(np_frames[0], diameter, invert=False, maxsize =maxsize, minmass = minmass, preprocess = True) #, minmass=50000)#130000)\n",
    "    f = tp.batch(np_frames[:300], diameter, invert=False, maxsize =maxsize, minmass = minmass,topn=topn,preprocess = True)#diameter, minmass=250);#50000);#130000, invert=False);\n",
    "    t = tp.link(f, search_ranges[i], memory=1,adaptive_stop=0.01, adaptive_step=0.98)\n",
    "    t1 = tp.filter_stubs(t, 15)\n",
    "    # Compare the number of particles in the unfiltered and filtered data.\n",
    "    print('Before:', t['particle'].nunique())\n",
    "    print('After:', t1['particle'].nunique())\n",
    "\n",
    "    t2 = t1#[((t1['mass'] > 100) & (t1['size'] < 5.0) )]\n",
    "    if len(t2) > 0:\n",
    "        plt.figure(figsize = [10,10])\n",
    "        tp.plot_traj(t2);\n",
    "        plt.show()\n",
    "\n",
    "    d = tp.compute_drift(t2)\n",
    "    tm = tp.subtract_drift(t2.copy(), d)\n",
    "\n",
    "    if len(tm) > 0:\n",
    "        plt.figure(figsize = [10,10])\n",
    "        tp.plot_traj(tm);\n",
    "        plt.savefig(str(i)+'.pdf')\n",
    "        plt.show()\n",
    "\n",
    "        im = tp.imsd(tm, voxel, fps)#.head(15)  # microns per pixel = 100/285., frames per second = 24\n",
    "        fig, ax = plt.subplots(figsize = [5,5])\n",
    "        ax.plot(im.index, im, 'k-', alpha=0.1)  # black lines, semitransparent\n",
    "        ax.set(ylabel=r'$\\langle \\Delta r^2 \\rangle$ [$\\mu$m$^2$]',\n",
    "               xlabel='lag time $t$')\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        plt.show()\n",
    "\n",
    "        em = tp.emsd(tm, voxel, fps).head(30) # microns per pixel = 100/285., frames per second = 24    \n",
    "        plt.figure(figsize = [5,5])\n",
    "        plt.ylabel(r'$\\langle \\Delta r^2 \\rangle$ [$\\mu$m$^2$]')\n",
    "        plt.xlabel('lag time $t$');\n",
    "        para = tp.utils.fit_powerlaw(em)  # performs linear best fit in log space, plots]\n",
    "        plt.show()\n",
    "        print(files[i][0])\n",
    "        print(para)\n",
    "        ns.append(para['n'][0])\n",
    "        As.append(para['A'][0])\n",
    "    else:\n",
    "        im = tm\n",
    "        em = tm\n",
    "\n",
    "\n",
    "    #tub_image = plt.imread('./'+categories[category-2]+'/Project004_Image '+str(get_image_num(files[i][0])-2)+'_RAW_ch00.tif')\n",
    "    #tub_h,tub_w = np.shape(tub_image)\n",
    "    #center_y, center_x = (int(tub_h/2),int(tub_w/2))\n",
    "    #half_sq_h,half_sq_w = (int(tub_h/2/2/2/2),int(tub_w/2/2/2/2))\n",
    "    #tub_center_median_intensities.append(np.median(tub_image[center_y-half_sq_h:center_y+half_sq_h,center_x-half_sq_w:center_x+half_sq_w].flatten())) # 40X -> 5X /2/2/2\n",
    "    #tub_center_mean_intensities.append(np.mean(tub_image[center_y-half_sq_h:center_y+half_sq_h,center_x-half_sq_w:center_x+half_sq_w].flatten())) # 40X -> 5X /2/2/2\n",
    "    #plt.imshow(tub_image)\n",
    "    #plt.show()\n",
    "    ims.append(im)\n",
    "    ems.append(em)\n",
    "    ds.append(d)\n",
    "    t2s.append(t2)\n",
    "    file_records.append(experiment_folder+'/'+files[i])\n",
    "\n",
    "list_ns.append(ns)\n",
    "list_As.append(As)\n",
    "#list_tub_center_median_intensities.append(tub_center_median_intensities)\n",
    "#list_tub_center_mean_intensities.append(tub_center_mean_intensities)\n",
    "list_ims.append(ims)\n",
    "list_ems.append(ems)\n",
    "list_ds.append(ds)\n",
    "list_t2s.append(t2s)\n",
    "list_file_records.append(file_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter = 15\n",
    "maxsize = 7\n",
    "minmass =1500\n",
    "percentile = 99.5\n",
    "topn = 300\n",
    "\n",
    "\n",
    "f = tp.locate(np_frames[0], diameter, invert=False, maxsize =maxsize, minmass = minmass, preprocess = False) #, minmass=50000)#130000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(f['mass'],bins=100);\n",
    "plt.xlim(0,3000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    plt.figure(figsize = [15,15])\n",
    "    plt.imshow(np_frames[i])\n",
    "    tp.annotate(t2[t2['frame'] == i], frames[i]);\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_t2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_cmap(nlabels, type='bright', first_color_black=True, last_color_black=False, verbose=True):\n",
    "    \"\"\"\n",
    "    Creates a random colormap to be used together with matplotlib. Useful for segmentation tasks\n",
    "    :param nlabels: Number of labels (size of colormap)\n",
    "    :param type: 'bright' for strong colors, 'soft' for pastel colors\n",
    "    :param first_color_black: Option to use first color as black, True or False\n",
    "    :param last_color_black: Option to use last color as black, True or False\n",
    "    :param verbose: Prints the number of labels and shows the colormap. True or False\n",
    "    :return: colormap for matplotlib\n",
    "    \"\"\"\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    import colorsys\n",
    "    import numpy as np\n",
    "\n",
    "\n",
    "    if type not in ('bright', 'soft'):\n",
    "        print ('Please choose \"bright\" or \"soft\" for type')\n",
    "        return\n",
    "\n",
    "    if verbose:\n",
    "        print('Number of labels: ' + str(nlabels))\n",
    "\n",
    "    # Generate color map for bright colors, based on hsv\n",
    "    if type == 'bright':\n",
    "        randHSVcolors = [(np.random.uniform(low=0.0, high=1),\n",
    "                          np.random.uniform(low=0.2, high=1),\n",
    "                          np.random.uniform(low=0.9, high=1)) for i in range(nlabels)]\n",
    "\n",
    "        # Convert HSV list to RGB\n",
    "        randRGBcolors = []\n",
    "        for HSVcolor in randHSVcolors:\n",
    "            randRGBcolors.append(colorsys.hsv_to_rgb(HSVcolor[0], HSVcolor[1], HSVcolor[2]))\n",
    "\n",
    "        if first_color_black:\n",
    "            randRGBcolors[0] = [0, 0, 0]\n",
    "\n",
    "        if last_color_black:\n",
    "            randRGBcolors[-1] = [0, 0, 0]\n",
    "\n",
    "        random_colormap = LinearSegmentedColormap.from_list('new_map', randRGBcolors, N=nlabels)\n",
    "\n",
    "    # Generate soft pastel colors, by limiting the RGB spectrum\n",
    "    if type == 'soft':\n",
    "        low = 0.6\n",
    "        high = 0.95\n",
    "        randRGBcolors = [(np.random.uniform(low=low, high=high),\n",
    "                          np.random.uniform(low=low, high=high),\n",
    "                          np.random.uniform(low=low, high=high)) for i in range(nlabels)]\n",
    "\n",
    "        if first_color_black:\n",
    "            randRGBcolors[0] = [0, 0, 0]\n",
    "\n",
    "        if last_color_black:\n",
    "            randRGBcolors[-1] = [0, 0, 0]\n",
    "        random_colormap = LinearSegmentedColormap.from_list('new_map', randRGBcolors, N=nlabels)\n",
    "\n",
    "    # Display colorbar\n",
    "    if verbose:\n",
    "        from matplotlib import colors, colorbar\n",
    "        from matplotlib import pyplot as plt\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 0.5))\n",
    "\n",
    "        bounds = np.linspace(0, nlabels, nlabels + 1)\n",
    "        norm = colors.BoundaryNorm(bounds, nlabels)\n",
    "\n",
    "        cb = colorbar.ColorbarBase(ax, cmap=random_colormap, norm=norm, spacing='proportional', ticks=None,\n",
    "                                   boundaries=bounds, format='%1i', orientation=u'horizontal')\n",
    "\n",
    "    return random_colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_cmap(np.max(f['particle']), type='bright', first_color_black=True, last_color_black=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(to_plot['x']+10,to_plot['y'],marker = '.', c = colors,  cmap=new_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "f = list_t2s[0][k]\n",
    "frames = pims.open(experiment_folder+'/'+files[k])\n",
    "overall_mean = np.mean(frames)\n",
    "np_frames = np.ones(np.shape(frames))\n",
    "for j,frame in enumerate(frames):\n",
    "    norm_frame = frame*overall_mean/np.mean(frame)/norm_flatfield\n",
    "    np_frames[j] = (norm_frame-np.percentile(np.array(norm_frame),50)).astype(int)\n",
    "new_cmap = rand_cmap(np.max(f['particle']), type='bright', first_color_black=True, last_color_black=False, verbose=True)\n",
    "for i in range(100):\n",
    "    plt.figure(figsize = [10,10])\n",
    "    #f = tp.locate(frames[i], 15, invert=False, minmass=1500)\n",
    "    #tp.annotate(f, frames[i])\n",
    "    to_plot = f.loc[f['frame']==i]\n",
    "    colors = to_plot['particle']\n",
    "    plt.imshow(np_frames[i])\n",
    "    plt.scatter(to_plot['x']+10,to_plot['y'],marker = '.', c = colors, cmap=new_cmap, vmin=0, vmax=np.max(f['particle']))\n",
    "    plt.xlim(0,1024)\n",
    "    plt.show()\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# obj0, obj1, obj2 are created here...\n",
    " \n",
    "# Saving the objects:\n",
    "#with open('050622_041822_objs1.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "#    pickle.dump([list_ns, list_As, list_ims,list_ems,list_ds,list_t2s,list_file_records], f)\n",
    "\n",
    "# Getting back the objects:\n",
    "#with open('041822_objs1.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
    "#    list_ns, list_As, list_ims,list_ems,list_ds,list_t2s,list_file_records = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(['extract_00']+['extr'+str(x*20) for x in range(0,6)]+['conc'+str(x*20) for x in range(0,11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_diffusion(x, D):\n",
    "    return D * x \n",
    "colors = plt.cm.viridis(np.linspace(0,1,11))\n",
    "Ds_list = []\n",
    "for i in range(len(list_ems[0])):\n",
    "    Ds = []\n",
    "    xdata = list_ims[0][i].index\n",
    "    for j in range(len(list_ims[0][i].columns)):\n",
    "        ydata = [x/4 for x in list_ims[0][i].iloc[:,j]]\n",
    "        popt, pcov = curve_fit(normal_diffusion, xdata[:3], ydata[:3])\n",
    "        plt.scatter(xdata,ydata,color = colors[i%11],marker= 'o')\n",
    "        plt.plot(xdata,normal_diffusion(xdata,popt[0]),color = colors[i%11])\n",
    "        plt.ylim(0,10)\n",
    "        Ds.append(popt[0])\n",
    "    Ds_list.append(Ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(x):\n",
    "    return np.std(x) / np.mean(x)\n",
    "colors = plt.cm.jet(np.linspace(0,1,6))\n",
    "plt.figure(figsize = [5,5])\n",
    "bins = np.linspace(0,8,100)\n",
    "for i,Ds in enumerate(Ds_list[1:7]):\n",
    "    a = np.histogram(Ds,bins = bins,density=True);\n",
    "    plt.step(bins[:-1],a[0]+i,color = 'black',alpha = i/7+1/7)\n",
    "    #plt.ylim(0,8)\n",
    "    print(cv(Ds))\n",
    "    dip, pval = diptest.diptest(np.array(Ds))\n",
    "    print((dip,pval))\n",
    "plt.xlabel(r'$D_{eff}$ ($\\mu m^2$/s)')\n",
    "plt.savefig('modality.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
